---
title: "R Notebook"
output: html_notebook
---


```{r}
library(rstanarm)
library(projpred)
library(ggplot2)
library(bayesplot)
theme_set(theme_classic())
options(mc.cores = parallel::detectCores())
```


## Load pre-processed and scaled Train and Test data
```{r}
training_data <- select(read_csv('../data/bankruptcy_train_am.csv'), -X1)
test_data <- select(read_csv('../data/bankruptcy_test_am.csv'), -X1)
```

## Run Bayesian Variable selection method projpred from already fitted "FULL" model.

### Load already fitted Full model
```{r}
full_model <- readRDS("../model/post1.rds")
```

```{r}
summary(full_model)
```

### Do Bayesian Projpred variable selection

```{r}
library(projpred)
```


```{r}
vs <- varsel(full_model, method='forward')
```

Run the variable selection and print out the variable ordering
```{r}
vs$vind
```

Plot the ELPD and classification accuracy on the training data:
```{r}
varsel_plot(vs, stats=c('elpd', 'acc'), deltas=F)
```

Cross-validate the full model and the variable selection
```{r}
t_prior <- student_t(df = 7, location = 0, scale = 2.5)
cvs <- cv_varsel(full_model, method='forward', cv_method='kfold', K=5, seed=42)
```

Above function : cvs <- cv_varsel(full_model, method='forward', cv_method='kfold', K=5, seed=42) , took almost 6 hours

```{r}
# model size suggested by the program
suggest_size(cvs)
```

```{r}
cvs$ssize
```

```{r}
# plot the validation results, this time relative to the full model
varsel_plot(cvs, stats = c('elpd', 'rmse'), deltas=T)
```
